{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9fb3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anush/anaconda3/lib/python3.9/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from resume_parser import resumeparse\n",
    "from tika import parser  \n",
    "import locationtagger\n",
    "import re\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from pdfminer.high_level import extract_text\n",
    "import aspose.words as aw\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import pathlib\n",
    "####################################################\n",
    "\n",
    "import glob\n",
    "from pdfminer.high_level import extract_text\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1944c907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anush/Desktop/flask_name/Training_resume'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = pathlib.Path(__name__).parent.absolute()\n",
    "pdf_folder_path = os.path.join(base_dir,'Training_resume',)\n",
    "pdf_file_path  = os.path.join(base_dir,'Training_resume','*')\n",
    "pdf_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1482f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_convert_to_pdf(path):\n",
    "#     count =0\n",
    "    cunt =0\n",
    "    cnt = 0\n",
    "    for file_ in glob.glob(path):\n",
    "        try:\n",
    "            if file_.endswith(\".doc\"):\n",
    "                doc = aw.Document(file_)\n",
    "                doc.save(os.path.join(base_dir,'Training_resume',f\"{cunt}.pdf\"))\n",
    "                cunt+=1\n",
    "            elif file_.endswith(\".rtf\"):\n",
    "                doc = aw.Document(file_)\n",
    "                doc.save(os.path.join(base_dir,'Training_resume',f\"{cunt}.pdf\"))\n",
    "                cnt+=1        \n",
    "        except  Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "#convert word to text\n",
    "def  extract_text_from_word(word_path):\n",
    "    doc = docx.Document(word_path)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)\n",
    "\n",
    "\n",
    "#convert pdf to text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "\n",
    "#return text\n",
    "def return_text(path):\n",
    "    if path.endswith('.docx'):\n",
    "        return extract_text_from_word(path)\n",
    "    elif path.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(path)\n",
    "    \n",
    "\n",
    "#convert_the_info_dic\n",
    "def convert_the_info_dic(text):\n",
    "    #breaking the text\n",
    "    dit ={}\n",
    "    title = ['Education','Qualification','Skills','Objective','Experience','Tools','Designation','Employment']\n",
    "    for i in title:\n",
    "        text = text.replace(f'{i}',f'|{i}').replace(f'{i.upper()}',f'|{i.upper()}')\n",
    "    text = text.split(\"|\")\n",
    "\n",
    "    #making dictionary of inforamtion\n",
    "    for titl in title:\n",
    "        check = False\n",
    "        for txt in text: \n",
    "            if titl in txt or titl.upper() in txt:\n",
    "                check = True\n",
    "                dit[titl] = txt \n",
    "        if check == False:\n",
    "            dit[titl] = 'Nan'\n",
    "    return dit\n",
    "\n",
    "\n",
    "#extraction_the_data\n",
    "def extraction_of_Data(resume_path,data_in_dic,text):\n",
    "    prev =[]\n",
    "    person =[]\n",
    "    city = []\n",
    "    education = []\n",
    "    skill =[]\n",
    "    doc = nlp(text)\n",
    "\n",
    "\n",
    "#     extraction of Education\n",
    "    edu_attribute = data_in_dic['Education']\n",
    "    education.append(edu_attribute)\n",
    "    \n",
    "    data1 = resumeparse.read_file(resume_path)\n",
    "    #extract the name\n",
    "    name_data = data1['name']\n",
    "    if 'Aspose Pty' == name_data:\n",
    "        people =[]\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\" or (ent.text.istitle()):\n",
    "                people.append(ent.text)\n",
    "        name_data = people[2]\n",
    "    elif 'curriculum vitae' == name_data.lower():\n",
    "        people =[]\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\" or (ent.text.istitle()):\n",
    "                people.append(ent.text)\n",
    "                break\n",
    "        name_data = people[0]\n",
    "    else:\n",
    "        name_data = name_data\n",
    "    #extract the email\n",
    "    email_data = data1['email']\n",
    "    #extract the phone\n",
    "    phone = data1['phone']\n",
    "    if str(phone)=='003-2023':\n",
    "        phone_pattern = re.compile(r'(?:\\+\\d{1,2}\\s)?\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}')\n",
    "        phone_numbers = re.findall(phone_pattern, text)\n",
    "        phone =phone_numbers[0]\n",
    "    else:\n",
    "        phone = phone\n",
    "\n",
    "    #extract the designition\n",
    "    designation_data = data1['designition']\n",
    "    \n",
    "    #extract the experience\n",
    "    experience_data = data1['total_exp']\n",
    "    if len([i for i in str(experience_data)])>2:\n",
    "        experience_data = None\n",
    "    else:\n",
    "        experience_data = experience_data\n",
    "        \n",
    "    #extract the skills\n",
    "#     skill_data = data1['skills']\n",
    "        \n",
    "    #extract the New_skills    \n",
    "    skill_attribute = data_in_dic['Skills']\n",
    "    if str(skill_attribute) =='Nan':\n",
    "        skill.append(data1['skills'])\n",
    "    else:\n",
    "        skill_attribute = data_in_dic['Skills']\n",
    "        skill.append(skill_attribute)\n",
    "    \n",
    "    #append the information \n",
    "#     prev.append(person)\n",
    "    prev.append(name_data)\n",
    "    prev.append(email_data)\n",
    "    prev.append(phone)\n",
    "    prev.append(skill)\n",
    "    prev.append(designation_data)\n",
    "    prev.append(experience_data)\n",
    "    prev.append(education)\n",
    "#     prev.append(city)\n",
    "#location\n",
    "    place_entity = locationtagger.find_locations(text = text)\n",
    "    prev.append(str(place_entity.countries))\n",
    "    prev.append(str(place_entity.regions))\n",
    "    prev.append(str(place_entity.cities))\n",
    "    prev.append(resume_path)\n",
    "    return prev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176c6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Name', 'Email','Mobile','Skills','Designation','Experience_Period','education','countries','regions','cities','Resume_Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f367a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anush/Desktop/flask_name/Training_resume/* ggggggggggggggggggg\n",
      "/home/anush/Desktop/flask_name/Training_resume/RESUME.doc kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/drew2019.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/carol resume.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/Analecia Moore 954.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/SARA'S RESUME.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Resume (1).pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Cecilia Morales Resume.rtf kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/yajaira mercedes (1).pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Ashley Resume 2.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/Resume3.rtf kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/0.pdf kkkkkkkkkkkkkkkkkk\n",
      "list index out of range\n",
      "/home/anush/Desktop/flask_name/Training_resume/Christine Colangelo Resume.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Joey Payne- Resume 2019.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/CAROLINA NARBUTAS- resume (1).pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Idalis Resume.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/resume.docx.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Lleyni Perez Resume..pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Brandi Shady Resume.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Administrative_Assistant___Office_Manager_20180201.doc.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Document.rtf kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/Pamela Randhan Resume_2019.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/resume.docx 2.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Lisa Resume 2018.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/2.pdf kkkkkkkkkkkkkkkkkk\n",
      "list index out of range\n",
      "/home/anush/Desktop/flask_name/Training_resume/Resume 2019.doc kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/resume.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/Kasandra-Abbott.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/General Resume.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/Shawn Findlater Resume02.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/resume.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Resume Sandi Barlow.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/1.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Elizabeth Cuty - Resume.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Kassandra-Diaz.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Resume Valentina  2019.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/Resume 1.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/William Feis Resume 2019 William Feis.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/KISS Innovations BP.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Daniel Nyhuis Resume 11-2018.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/attachment 1.docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/JLittle2018Resume1c.doc kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/1556900372217_1554417453464_1551157904500_1550589166088_1549738472422_1548191684505_1547929350597_1547659059203_Jessica new updated HR  resume (1) (1).docx kkkkkkkkkkkkkkkkkk\n",
      "/home/anush/Desktop/flask_name/Training_resume/resume __.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n",
      "/home/anush/Desktop/flask_name/Training_resume/Teresa A F Resume OJT.pdf kkkkkkkkkkkkkkkkkk\n",
      "ghhhhhhhhhhhhhhhhhhhhhhhh\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_convert_to_pdf(pdf_file_path)\n",
    "print(pdf_file_path,'ggggggggggggggggggg')\n",
    "for path_of_list in glob.glob(pdf_file_path):\n",
    "    print(path_of_list,'kkkkkkkkkkkkkkkkkk')\n",
    "    if path_of_list.endswith(\".pdf\"):\n",
    "        try:\n",
    "            text = return_text(path_of_list)\n",
    "            data_in_dic = convert_the_info_dic(text)\n",
    "            data = extraction_of_Data(path_of_list,data_in_dic, text)\n",
    "    ########################creating the dataframe###############################\n",
    "            df.loc[-1] = data\n",
    "            df.reset_index(drop ='index',inplace =True)\n",
    "            print('ghhhhhhhhhhhhhhhhhhhhhhhh')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    elif path_of_list.endswith(\".pdf\"):\n",
    "        try:\n",
    "            text = return_text(path_of_list)\n",
    "            data_in_dic = convert_the_info_dic(text)\n",
    "            data = extraction_of_Data(path_of_list,data_in_dic, text)\n",
    "    ########################creating the dataframe###############################\n",
    "            df.loc[-1] = data\n",
    "            df.reset_index(drop ='index',inplace =True)\n",
    "            print('ghhhhhhhhhhhhhhhhhhhhhhhh')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07088a12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Experience_Period</th>\n",
       "      <th>education</th>\n",
       "      <th>countries</th>\n",
       "      <th>regions</th>\n",
       "      <th>cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DREW MENDEZ</td>\n",
       "      <td>DREW.MENDEZ@AOL.COM</td>\n",
       "      <td>(646)633-2926</td>\n",
       "      <td>[SKILLS : \\n\\nSoftware: Microsoft; Powerpoint;...</td>\n",
       "      <td>[student, customer service manager, service ma...</td>\n",
       "      <td>None</td>\n",
       "      <td>[EDUCATION : \\n\\nLAGUARDIA COMMUNITY COLLEGE, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Reading']</td>\n",
       "      <td>['Reading', 'Ridgewood', 'Long Island City', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sara Lopez</td>\n",
       "      <td>Email-slopez7571@yahoo.com</td>\n",
       "      <td>561-354-8002</td>\n",
       "      <td>[[salads, desserts, saint, go, email, fit, wri...</td>\n",
       "      <td>[service manager, radiologic technician, techn...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Education\\n\\n•Graduate 2015- Fort Pierce Cent...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Indian River', 'Frank']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice Brown</td>\n",
       "      <td>jaisnana11@GMAIL.COM</td>\n",
       "      <td>(239)672-5433</td>\n",
       "      <td>[Skills \\n\\nCustomer Service \\n\\n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Education \\n\\nMONTH  10-2010  \\n\\nSt. James A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Florida']</td>\n",
       "      <td>['Melbourne', 'Florida']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yajaira Mercedes</td>\n",
       "      <td>tequiero1@msn.com</td>\n",
       "      <td>(401) 440-9858</td>\n",
       "      <td>[[office administration, devices, drive, train...</td>\n",
       "      <td>[office administration, office support, qualit...</td>\n",
       "      <td>9</td>\n",
       "      <td>[Education and Training  \\n\\n03/2015 - 07/2018...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Taunton', 'West Haven', 'Providence', 'Johns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christine Colangelo</td>\n",
       "      <td>christineleecolangelo@gmail.com</td>\n",
       "      <td>(772) 444.5944</td>\n",
       "      <td>[SKILLS \\n\\n● Types 80+ WPM \\n● Received 17 Ce...</td>\n",
       "      <td>[office manager, long term, owner, warehouse m...</td>\n",
       "      <td>10</td>\n",
       "      <td>[EDUCATION \\n\\nPSLHS, Port Saint Lucie \\n\\n- \\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Port Saint Lucie', 'Christine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAROLINA NARBUTAS</td>\n",
       "      <td>carolinanarbutas@gmail.com</td>\n",
       "      <td>973-862-9739</td>\n",
       "      <td>[SKILLS \\n\\n•  Reliable, punctual and honest p...</td>\n",
       "      <td>[office manager, property manager, real estate...</td>\n",
       "      <td>0</td>\n",
       "      <td>[EDUCATION \\n\\nDECEMBER 2015 \\nREAL ESTATE AGE...</td>\n",
       "      <td>['MEXICO']</td>\n",
       "      <td>['Florida']</td>\n",
       "      <td>['Mexico', 'Stuart', 'Carolina', 'Florida', 'R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Idalisbraddy@hotmail.com</td>\n",
       "      <td>772-336-8212</td>\n",
       "      <td>[[f, x, e-mail, redwood, holidays, o, n, mail,...</td>\n",
       "      <td>[full time, part time, store manager, patient ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Nan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Golden', 'Jensen Beach', 'Johnston', 'Contact']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Christine Thermilus</td>\n",
       "      <td>livingnparadise@comcast.net</td>\n",
       "      <td>772 618 0992</td>\n",
       "      <td>[[e-mail, autism, core strength, saint, readin...</td>\n",
       "      <td>[front desk]</td>\n",
       "      <td>12</td>\n",
       "      <td>[Education:\\n\\nLa Salle High School           ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Miami', 'Port Saint Lucie', 'Davie', 'Christ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lleyni Perez</td>\n",
       "      <td>Perezln29@gmail.com</td>\n",
       "      <td>772-380-6956</td>\n",
       "      <td>[Skills:  40 wpm, Microsoft Word, Microsoft Ex...</td>\n",
       "      <td>[administrative assistant, production assistan...</td>\n",
       "      <td>12</td>\n",
       "      <td>[Education: South Fork High School      \\n\\nSt...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Palm City', 'Spanish', 'English']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>772-200-9799</td>\n",
       "      <td>[[forms, team development, load, cost control,...</td>\n",
       "      <td>[part time, administrative assistant, office m...</td>\n",
       "      <td>0</td>\n",
       "      <td>[EDUCATION: \\nSt James Academy High School  \\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Sales', 'Part']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHRISTINE M</td>\n",
       "      <td>cnelson430@gmail.com</td>\n",
       "      <td>(772) 979-6868</td>\n",
       "      <td>[[work orders, pest, time management, payments...</td>\n",
       "      <td>[administrative assistant, office manager]</td>\n",
       "      <td>11</td>\n",
       "      <td>[Nan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Nelson']</td>\n",
       "      <td>['Nelson', 'Palm City', 'Port Saint Lucie', 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PAMELA RANDHAN</td>\n",
       "      <td>pamelamarie76@yahoo.com</td>\n",
       "      <td>(772) 501-9795</td>\n",
       "      <td>[SKILLS \\n\\n•  Proficient in Microsoft Office ...</td>\n",
       "      <td>[assistant manager, store manager, part time, ...</td>\n",
       "      <td>23</td>\n",
       "      <td>[EDUCATION \\n\\n       •      Fort Pierce Centr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Florida']</td>\n",
       "      <td>['Okeechobee', 'Winter Haven', 'Florida', 'Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Christine Thermilus</td>\n",
       "      <td>livingnparadise@comcast.net</td>\n",
       "      <td>772 618 0992</td>\n",
       "      <td>[[e-mail, autism, core strength, saint, readin...</td>\n",
       "      <td>[front desk]</td>\n",
       "      <td>12</td>\n",
       "      <td>[Education:\\n\\nLa Salle High School           ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Miami', 'Port Saint Lucie', 'Davie', 'Christ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>​Lisa Wilson</td>\n",
       "      <td>LW82734@gmail.com</td>\n",
       "      <td></td>\n",
       "      <td>[Skills\\nMedical Terminology                  ...</td>\n",
       "      <td>[customer service representative, service repr...</td>\n",
       "      <td>15</td>\n",
       "      <td>[EDUCATION\\n\\nMarch, 2008\\n\\nJanuary, 2007   \\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Florida']</td>\n",
       "      <td>['Stuart', 'Florida']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kasandra Abbott</td>\n",
       "      <td>klei80sbaby@gmail.com</td>\n",
       "      <td>7725012977</td>\n",
       "      <td>[Skills\\n\\nExcel (2 years), Microsoft Office (...</td>\n",
       "      <td>[administrative assistant, office assistant, o...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Education\\n\\nHigh School Diploma\\nHome school...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Melbourne', 'Vero Beach', 'Sebastian', 'Outl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yahoo Mail</td>\n",
       "      <td>(jenniferoneil3985@gmail.com)</td>\n",
       "      <td>342-2106</td>\n",
       "      <td>[[forms, props, training, customer, stocking, ...</td>\n",
       "      <td>[department manager, portrait consultant, chil...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Nan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['March', 'West Palm Beach', 'Palm City', 'Stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Carol M. Cobb</td>\n",
       "      <td>carolmcobb@gmail.com</td>\n",
       "      <td>512-673-3033</td>\n",
       "      <td>[Skills\\nMarketing Strategies\\n\\nOrganizationa...</td>\n",
       "      <td>[facilitator, change management, real estate a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Educational Consultant\\nPeople's Publishing\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Aurora', 'Port Saint Lucie', 'Deming']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Elizabeth Cuty</td>\n",
       "      <td>Ecuty4840@gmail.com</td>\n",
       "      <td>772-475-4840</td>\n",
       "      <td>[Skills &amp; Abilities \\n\\nQuickBooks Pro, Window...</td>\n",
       "      <td>[office manager, president, notary public]</td>\n",
       "      <td>15</td>\n",
       "      <td>[Education \\n\\nHIGH SCHOOL DIPLOMA ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Elizabeth', 'Outlook']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kassandra Diaz</td>\n",
       "      <td>kassy.diaz93@gmail.com</td>\n",
       "      <td>7722379678</td>\n",
       "      <td>[Skills\\n\\ninventory management, telxon use, p...</td>\n",
       "      <td>[pharmacy technician, technician, sales associ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Education\\n\\nPharmacy\\n\\n \\n \\n\f",
       "Walmart PTU -...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Homestead', 'Us']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>West Palm</td>\n",
       "      <td>Mrs.Laboy@outlook.com</td>\n",
       "      <td>5612811317</td>\n",
       "      <td>[SkillsFaxing documentsScheduling and calendar...</td>\n",
       "      <td>[administrative assistant, accountant, account...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Education and TrainingHigh School DiplomaPalm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['West Palm Beach', 'Spanish', 'Sales', 'Engli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>William Feis</td>\n",
       "      <td>xspy2000@live.com</td>\n",
       "      <td>772-925-1274</td>\n",
       "      <td>[[attorneys, foundation, drive, personal secur...</td>\n",
       "      <td>[service inspector, inspector, collector, publ...</td>\n",
       "      <td>36</td>\n",
       "      <td>[EDUCATION:\\nSouthern Career, Boca Raton, Flor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Florida', 'New Jersey']</td>\n",
       "      <td>['Boca Raton', 'Vero Beach', 'Belmar', 'Bayvil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>OVERVIEW SERVICE</td>\n",
       "      <td>None</td>\n",
       "      <td>585 2018</td>\n",
       "      <td>[[fits, tax, ratings, application, traction, i...</td>\n",
       "      <td>[founder, founder and ceo, ceo, operations pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Nan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Florida']</td>\n",
       "      <td>['March', 'Florida', 'Jones', 'Don', 'Monster'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Donna DiRoma</td>\n",
       "      <td>Darkstar1dd@gmail.com</td>\n",
       "      <td>718-775-2563</td>\n",
       "      <td>[Skills     \\n\\nCustomer Relations \\nComputer ...</td>\n",
       "      <td>[customer service agent, service agent, admitt...</td>\n",
       "      <td>35</td>\n",
       "      <td>[Education \\n\\nMt. Vernon High School   Mt. Ve...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Donna']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Teresa Fogarty</td>\n",
       "      <td>teresa92178@gmail.com​</td>\n",
       "      <td>(772) 834-3245</td>\n",
       "      <td>[Skills Summary: \\n]</td>\n",
       "      <td>[collections specialist, regional director, di...</td>\n",
       "      <td>24</td>\n",
       "      <td>[Education\\n\\nMolloy College\\nCertified Medica...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['March', 'Fort Myers', 'Key West', 'Vero Beac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                            Email          Mobile  \\\n",
       "0           DREW MENDEZ              DREW.MENDEZ@AOL.COM   (646)633-2926   \n",
       "1            Sara Lopez       Email-slopez7571@yahoo.com    561-354-8002   \n",
       "2           Alice Brown             jaisnana11@GMAIL.COM   (239)672-5433   \n",
       "3      Yajaira Mercedes                tequiero1@msn.com  (401) 440-9858   \n",
       "4   Christine Colangelo  christineleecolangelo@gmail.com  (772) 444.5944   \n",
       "5     CAROLINA NARBUTAS       carolinanarbutas@gmail.com    973-862-9739   \n",
       "6                               Idalisbraddy@hotmail.com    772-336-8212   \n",
       "7   Christine Thermilus      livingnparadise@comcast.net    772 618 0992   \n",
       "8          Lleyni Perez              Perezln29@gmail.com    772-380-6956   \n",
       "9                                                   None    772-200-9799   \n",
       "10          CHRISTINE M             cnelson430@gmail.com  (772) 979-6868   \n",
       "11       PAMELA RANDHAN          pamelamarie76@yahoo.com  (772) 501-9795   \n",
       "12  Christine Thermilus      livingnparadise@comcast.net    772 618 0992   \n",
       "13         ​Lisa Wilson                LW82734@gmail.com                   \n",
       "14      Kasandra Abbott            klei80sbaby@gmail.com      7725012977   \n",
       "15           Yahoo Mail    (jenniferoneil3985@gmail.com)        342-2106   \n",
       "16        Carol M. Cobb             carolmcobb@gmail.com    512-673-3033   \n",
       "17       Elizabeth Cuty              Ecuty4840@gmail.com    772-475-4840   \n",
       "18       Kassandra Diaz           kassy.diaz93@gmail.com      7722379678   \n",
       "19            West Palm            Mrs.Laboy@outlook.com      5612811317   \n",
       "20         William Feis                xspy2000@live.com    772-925-1274   \n",
       "21     OVERVIEW SERVICE                             None        585 2018   \n",
       "22         Donna DiRoma            Darkstar1dd@gmail.com    718-775-2563   \n",
       "23       Teresa Fogarty           teresa92178@gmail.com​  (772) 834-3245   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   [SKILLS : \\n\\nSoftware: Microsoft; Powerpoint;...   \n",
       "1   [[salads, desserts, saint, go, email, fit, wri...   \n",
       "2                  [Skills \\n\\nCustomer Service \\n\\n]   \n",
       "3   [[office administration, devices, drive, train...   \n",
       "4   [SKILLS \\n\\n● Types 80+ WPM \\n● Received 17 Ce...   \n",
       "5   [SKILLS \\n\\n•  Reliable, punctual and honest p...   \n",
       "6   [[f, x, e-mail, redwood, holidays, o, n, mail,...   \n",
       "7   [[e-mail, autism, core strength, saint, readin...   \n",
       "8   [Skills:  40 wpm, Microsoft Word, Microsoft Ex...   \n",
       "9   [[forms, team development, load, cost control,...   \n",
       "10  [[work orders, pest, time management, payments...   \n",
       "11  [SKILLS \\n\\n•  Proficient in Microsoft Office ...   \n",
       "12  [[e-mail, autism, core strength, saint, readin...   \n",
       "13  [Skills\\nMedical Terminology                  ...   \n",
       "14  [Skills\\n\\nExcel (2 years), Microsoft Office (...   \n",
       "15  [[forms, props, training, customer, stocking, ...   \n",
       "16  [Skills\\nMarketing Strategies\\n\\nOrganizationa...   \n",
       "17  [Skills & Abilities \\n\\nQuickBooks Pro, Window...   \n",
       "18  [Skills\\n\\ninventory management, telxon use, p...   \n",
       "19  [SkillsFaxing documentsScheduling and calendar...   \n",
       "20  [[attorneys, foundation, drive, personal secur...   \n",
       "21  [[fits, tax, ratings, application, traction, i...   \n",
       "22  [Skills     \\n\\nCustomer Relations \\nComputer ...   \n",
       "23                               [Skills Summary: \\n]   \n",
       "\n",
       "                                          Designation Experience_Period  \\\n",
       "0   [student, customer service manager, service ma...              None   \n",
       "1   [service manager, radiologic technician, techn...                 0   \n",
       "2                                                  []                 2   \n",
       "3   [office administration, office support, qualit...                 9   \n",
       "4   [office manager, long term, owner, warehouse m...                10   \n",
       "5   [office manager, property manager, real estate...                 0   \n",
       "6   [full time, part time, store manager, patient ...                 0   \n",
       "7                                        [front desk]                12   \n",
       "8   [administrative assistant, production assistan...                12   \n",
       "9   [part time, administrative assistant, office m...                 0   \n",
       "10         [administrative assistant, office manager]                11   \n",
       "11  [assistant manager, store manager, part time, ...                23   \n",
       "12                                       [front desk]                12   \n",
       "13  [customer service representative, service repr...                15   \n",
       "14  [administrative assistant, office assistant, o...                 8   \n",
       "15  [department manager, portrait consultant, chil...                20   \n",
       "16  [facilitator, change management, real estate a...                 0   \n",
       "17         [office manager, president, notary public]                15   \n",
       "18  [pharmacy technician, technician, sales associ...                11   \n",
       "19  [administrative assistant, accountant, account...                 0   \n",
       "20  [service inspector, inspector, collector, publ...                36   \n",
       "21  [founder, founder and ceo, ceo, operations pro...                 0   \n",
       "22  [customer service agent, service agent, admitt...                35   \n",
       "23  [collections specialist, regional director, di...                24   \n",
       "\n",
       "                                            education   countries  \\\n",
       "0   [EDUCATION : \\n\\nLAGUARDIA COMMUNITY COLLEGE, ...          []   \n",
       "1   [Education\\n\\n•Graduate 2015- Fort Pierce Cent...          []   \n",
       "2   [Education \\n\\nMONTH  10-2010  \\n\\nSt. James A...          []   \n",
       "3   [Education and Training  \\n\\n03/2015 - 07/2018...          []   \n",
       "4   [EDUCATION \\n\\nPSLHS, Port Saint Lucie \\n\\n- \\...          []   \n",
       "5   [EDUCATION \\n\\nDECEMBER 2015 \\nREAL ESTATE AGE...  ['MEXICO']   \n",
       "6                                               [Nan]          []   \n",
       "7   [Education:\\n\\nLa Salle High School           ...          []   \n",
       "8   [Education: South Fork High School      \\n\\nSt...          []   \n",
       "9   [EDUCATION: \\nSt James Academy High School  \\n...          []   \n",
       "10                                              [Nan]          []   \n",
       "11  [EDUCATION \\n\\n       •      Fort Pierce Centr...          []   \n",
       "12  [Education:\\n\\nLa Salle High School           ...          []   \n",
       "13  [EDUCATION\\n\\nMarch, 2008\\n\\nJanuary, 2007   \\...          []   \n",
       "14  [Education\\n\\nHigh School Diploma\\nHome school...          []   \n",
       "15                                              [Nan]          []   \n",
       "16  [Educational Consultant\\nPeople's Publishing\\n...          []   \n",
       "17               [Education \\n\\nHIGH SCHOOL DIPLOMA ]          []   \n",
       "18  [Education\\n\\nPharmacy\\n\\n \\n \\n\n",
       "Walmart PTU -...          []   \n",
       "19  [Education and TrainingHigh School DiplomaPalm...          []   \n",
       "20  [EDUCATION:\\nSouthern Career, Boca Raton, Flor...          []   \n",
       "21                                              [Nan]          []   \n",
       "22  [Education \\n\\nMt. Vernon High School   Mt. Ve...          []   \n",
       "23  [Education\\n\\nMolloy College\\nCertified Medica...          []   \n",
       "\n",
       "                      regions  \\\n",
       "0                 ['Reading']   \n",
       "1                          []   \n",
       "2                 ['Florida']   \n",
       "3                          []   \n",
       "4                          []   \n",
       "5                 ['Florida']   \n",
       "6                          []   \n",
       "7                          []   \n",
       "8                          []   \n",
       "9                          []   \n",
       "10                 ['Nelson']   \n",
       "11                ['Florida']   \n",
       "12                         []   \n",
       "13                ['Florida']   \n",
       "14                         []   \n",
       "15                         []   \n",
       "16                         []   \n",
       "17                         []   \n",
       "18                         []   \n",
       "19                         []   \n",
       "20  ['Florida', 'New Jersey']   \n",
       "21                ['Florida']   \n",
       "22                         []   \n",
       "23                         []   \n",
       "\n",
       "                                               cities  \n",
       "0   ['Reading', 'Ridgewood', 'Long Island City', '...  \n",
       "1                           ['Indian River', 'Frank']  \n",
       "2                            ['Melbourne', 'Florida']  \n",
       "3   ['Taunton', 'West Haven', 'Providence', 'Johns...  \n",
       "4                   ['Port Saint Lucie', 'Christine']  \n",
       "5   ['Mexico', 'Stuart', 'Carolina', 'Florida', 'R...  \n",
       "6   ['Golden', 'Jensen Beach', 'Johnston', 'Contact']  \n",
       "7   ['Miami', 'Port Saint Lucie', 'Davie', 'Christ...  \n",
       "8                 ['Palm City', 'Spanish', 'English']  \n",
       "9                                   ['Sales', 'Part']  \n",
       "10  ['Nelson', 'Palm City', 'Port Saint Lucie', 'S...  \n",
       "11  ['Okeechobee', 'Winter Haven', 'Florida', 'Out...  \n",
       "12  ['Miami', 'Port Saint Lucie', 'Davie', 'Christ...  \n",
       "13                              ['Stuart', 'Florida']  \n",
       "14  ['Melbourne', 'Vero Beach', 'Sebastian', 'Outl...  \n",
       "15  ['March', 'West Palm Beach', 'Palm City', 'Stu...  \n",
       "16           ['Aurora', 'Port Saint Lucie', 'Deming']  \n",
       "17                           ['Elizabeth', 'Outlook']  \n",
       "18                                ['Homestead', 'Us']  \n",
       "19  ['West Palm Beach', 'Spanish', 'Sales', 'Engli...  \n",
       "20  ['Boca Raton', 'Vero Beach', 'Belmar', 'Bayvil...  \n",
       "21  ['March', 'Florida', 'Jones', 'Don', 'Monster'...  \n",
       "22                                          ['Donna']  \n",
       "23  ['March', 'Fort Myers', 'Key West', 'Vero Beac...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af09d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(base_dir,'data_csv','client22.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0312e3",
   "metadata": {},
   "source": [
    "# data-Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a56df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cities(x):\n",
    "#     x =x[1:-1]\n",
    "#     doc = nlp(x)\n",
    "#     citi=[]\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == 'GPE'or ent.label_ =='NORP' or ent.label_ == 'FAC':\n",
    "#             citi.append(ent.text)\n",
    "#     return citi\n",
    "\n",
    "# df['cities'] = df['cities'].apply(lambda x :cities(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e977ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('resume_extration_2_5000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bdb045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('resume_extration_2_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d1b189",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'New_Skill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'New_Skill'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_122548/1712732635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'New_Skill'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'jjjjjjjjjjjjjjjjjjjjjjjjj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'New_Skill'"
     ]
    }
   ],
   "source": [
    "for i in df['New_Skill']:\n",
    "    print(i,'jjjjjjjjjjjjjjjjjjjjjjjjj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257cca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##education_____________\n",
    "\n",
    "# ad = r'Created\\s+with\\s+an\\s+evaluation\\s+copy\\s+of\\s+Aspose\\.Words\\.\\s+To\\s+discover\\s+the\\s+full\\s+versions\\s+of\\s+our\\s+APIs\\s+please\\s+visit:\\s+https://products\\.aspose\\.com/words/'\n",
    "# df['New_Skill'] =df['New_Skill'].apply(lambda x : re.sub(ad, \"\", x))\n",
    "# a,b,c,d,e= '\\\\x0c','\\\\xa0','\\\\u200b','Education','EDUCATION'\n",
    "# dat = [i.replace(a, '').replace(b,'').replace(c,'').replace(d,'').replace(e,'') for i in df['New_Skill'].values]\n",
    "# df['New_Skill'] = dat\n",
    "# df['New_Skill'].replace('\\t',\"\")\n",
    "# df['New_Skill'].replace('\\n',\"\")\n",
    "# df['New_Skill'].replace('\\n\\n',\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['New_Skill'].replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", r'\\r+|\\n+|\\t+',r\"\\t|\\n|\\r\"], value=[\"\",\"\",\"\"], regex=True, inplace=True)\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'@[\\S]+', '', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'&[\\S]+?;', '', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'#', ' ', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'(\\bRT\\b|\\bQT\\b)', '', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'http[\\S]+', '', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'\\w*\\d\\w*', r'', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'\\s\\s+', ' ', str(x)))\n",
    "df.New_Skill = df.New_Skill.apply(lambda x: re.sub(r'(\\A\\s+|\\s+\\Z)', '', str(x)))\n",
    "df['New_Skill'].replace('\\t',\"\").replace('\\n',\"\").replace('\\n\\n',\"\").replace(\"\\\\\",\"\")\n",
    "df.New_Skill.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d08de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "df['New_Skill']= df['New_Skill'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    text = re.split('\\W+', str(text))\n",
    "    return text\n",
    "\n",
    "df.New_Skill = df['New_Skill'].apply(lambda x: tokenization(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d200d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    treebank_tag =str(treebank_tag)\n",
    "    if treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def lemmatzer(text):\n",
    "    words_and_tags = nltk.pos_tag(text)\n",
    "    lem = []\n",
    "    for word, tag in words_and_tags:\n",
    "        lemma = wn.lemmatize(word,pos =get_wordnet_pos(tag))\n",
    "        lem.append(lemma)\n",
    "    return lem\n",
    "\n",
    "\n",
    "df.New_Skill= df.New_Skill.apply(lambda x: lemmatzer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec11725",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.New_Skill:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497a334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
